1) Differnece between Mutex and semaphores
	- Mutexes are very useful to protect data (critical section) from race conditions. Semaphores are usually used to synchronize threads more than to protect critical section.
	-  The reason for that is that semaphores do not have any ownership. A mutex can be released only by the thread that acquired it (a thread gets ownership of a mutex when waking from a mutex wait). 		However for semaphores any thread (or main) can initialize them to locked (0), and any thread can wait on them (blocks on 0 and decrements its value after) or post to them (increments its value)

2) Here are the rules for debugging stack corruption:

    If a crash is observed when a function returns, this might be due to stack corruption. The return address on the stack might have been corrupted by stack operations of called functions.
    Crash after an interrupt service routine returns might also be caused by stack corruption.
    Stack corruption can also be suspected when a passed parameter seems to have a value different from the one passed by the calling function. 
    When a stack corruption is detected, one should look at the local variables in the called and calling functions to look for possible sources of memory corruption. Check array and pointer declarations for sources of errors.
    Sometimes stray corruption of a processors registers might also be due to a stack corruption. If a register gets corrupted due to no reason, one possibility is that an offending thread or program corrupted the register context on the stack. When the register is restored as a part of a context switch, the task crashes.
    Corruption in heap can trickle down to the stack.
    Stack overflow takes place when a programs function nesting exceeds the stack allocated to the program. This can cause a stack area or heap area corruption. (Depends upon who attempts to access the corrupted memory first, a heap operation or stack operation).

3) What is the difference between a thread and a process?

	1. Threads are easier to create than processes since they 
	don't require a separate address space.
	2. Multithreading requires careful programming since threads 
	share data strucures that should only be modified by one thread
	at a time.  Unlike threads, processes don't share the same 
	address space.
	3.  Threads are considered lightweight because they use far 
	less resources than processes.
	4.  Processes are independent of each other.  Threads, since they 
	share the same address space are interdependent, so caution 
	must be taken so that different threads don't step on each other.  
	This is really another way of stating #2 above.
	5.  A process can consist of multiple threads.
	6.The processes and threads are independent sequences of execution, the typical difference is that threads run in a shared memory space, while processes run in separate memory spaces.
	A process has a self contained execution environment that means it has a complete, private set of basic run time resources purticularly each process has its own memory space. Threads exist within a		process and every process has at least one thread.
	Each process provides the resources needed to execute a program. Each process is started with a single thread, known as the primary thread. A process can have multiple threads in addition to the pr		imary thread.
	On a multiprocessor system, multiple processes can be executed in parallel. Multiple threads of control can exploit the true parallelism possible on multiprocessor systems.
	Threads have direct access to the data segment of its process but a processes have their own copy of the data segment of the parent process.
	Changes to the main thread may affect the behavior of the other threads of the process while changes to the parent process does not affect child processes.
	Processes are heavily dependent on system resources available while threads require minimal amounts of resource, so a process is considered as heavyweight while a thread is termed as a lightweight 		process.

3.1) Multi-threding and Multi-procesing?
	Multi-threading refers to an application with multiple threads running within a process, while multi-processing refers to an application organised across multiple OS-level processes.
	A thread is a stream of instructions within a process. Each thread has its own instruction pointer, set of registers and stack memory. The virtual address space is process specific, or common to 	     	all threads within a process. So, data on the heap can be readily accessed by all threads, for good or ill.
	Multi-threading is a more "light weight" form of concurrency: there is less context per thread than per process. As a result thread lifetime, context switching and synchronisation costs are lower. 	     The shared address space (noted above) means data sharing requires no extra work.
	Multi-processing has the opposite benefits. Since processes are insulated from each other by the OS, an error in one process cannot bring down another process. Contrast this with multi-threading, 
	in which an error in one thread can bring down all the threads in the process. Further, individual processes may run as different users and have different permissions.


4)Volatile

	1. The volatile type qualifier can be used to declare objects that may be modified in ways unknown to the compiler or have other unknown side effects (e.g. modification via a signal interrupt, 
	hardware register, or memory mapped I/O). Subject to the implementation-defined abstract machine, volatile objects inhibit some optimizations such as keeping the objects in registers and some types 	     of code motion.
	2.Higher optimization levels can reveal problems in some programs that are not apparent at lower optimization levels, for example, missing volatile qualifiers.
	This can manifest itself in a number of ways. Code might become stuck in a loop while polling hardware, multi-threaded code might exhibit strange behavior, or optimization might result in the 
	removal of code that implements deliberate timing delays. In such cases, it is possible that some variables are required to be declared as volatile.
	The declaration of a variable as volatile tells the compiler that the variable can be modified at any time externally to the implementation, for example, by the operating system, by another thread 		of execution such as an interrupt routine or signal handler, or by hardware. Because the value of a volatile-qualified variable can change at any time, the actual variable in memory must always 	be accessed whenever the variable is referenced in code. This means the compiler cannot perform optimizations on the variable, for example, caching its value in a register to avoid memory accesses. 
	Similarly, when used in the context of implementing a sleep or timer delay, declaring a variable as volatile tells the compiler that a specific type of behavior is intended, and that such code must		 not be optimized in such a way that it removes the intended functionality.
	In contrast, when a variable is not declared as volatile, the compiler can assume its value cannot be modified in unexpected ways. Therefore, the compiler can perform optimizations on the variable.
	The use of the volatile keyword is illustrated in the two sample routines of the following table. Both of these routines loop reading a buffer until a status flag buffer_full is set to true. The st	     ate of buffer_full can change asynchronously with program flow. 
